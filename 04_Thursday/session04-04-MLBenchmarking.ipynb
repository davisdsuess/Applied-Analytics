{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92fd1fb8",
   "metadata": {},
   "source": [
    "# Coding Block 4 - Automated model and hyperparameter tuning with AutoGluon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39695e0",
   "metadata": {},
   "source": [
    "### Load the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2b0c94e",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-09-20T20:03:00.442022Z",
     "iopub.status.busy": "2021-09-20T20:03:00.441258Z",
     "iopub.status.idle": "2021-09-20T20:03:01.852024Z",
     "shell.execute_reply": "2021-09-20T20:03:01.851352Z",
     "shell.execute_reply.started": "2021-09-20T19:54:12.026788Z"
    },
    "papermill": {
     "duration": 1.435807,
     "end_time": "2021-09-20T20:03:01.852223",
     "exception": false,
     "start_time": "2021-09-20T20:03:00.416416",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install autogluon.tabular  > /dev/null 2>&1\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "# AutoML\n",
    "from autogluon.tabular import TabularPredictor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aaae9e8",
   "metadata": {},
   "source": [
    "### Read the dataset \n",
    "You can also compare processed and non-processed data. The autogluon library will do some preprocessing as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1775d95",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-09-20T20:03:01.895944Z",
     "iopub.status.busy": "2021-09-20T20:03:01.895175Z",
     "iopub.status.idle": "2021-09-20T20:03:05.794695Z",
     "shell.execute_reply": "2021-09-20T20:03:05.795244Z",
     "shell.execute_reply.started": "2021-09-20T19:54:12.050571Z"
    },
    "papermill": {
     "duration": 3.924865,
     "end_time": "2021-09-20T20:03:05.795452",
     "exception": false,
     "start_time": "2021-09-20T20:03:01.870587",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_cleaned = pd.read_csv(\"../data/df_imputed_clean.csv\")\n",
    "data = pd.read_csv(\"../data/df_imputed_clean.csv\")\n",
    "data = data.drop(columns=['Mahalanobis_Distance','Multivariate_Outlier','Outlier'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2661bd7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20250320_140736\"\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20250320_140736\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.9.21\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          32\n",
      "Memory Avail:       3.52 GB / 15.63 GB (22.5%)\n",
      "Disk Space Avail:   672.42 GB / 924.37 GB (72.7%)\n",
      "===================================================\n",
      "Train Data Rows:    729\n",
      "Train Data Columns: 9\n",
      "Label Column:       Outcome\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [1.0, 0.0]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3602.75 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.05 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 8 | ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', ...]\n",
      "\t\t('int', [])   : 1 | ['Unnamed: 0']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 8 | ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', ...]\n",
      "\t\t('int', [])   : 1 | ['Unnamed: 0']\n",
      "\t0.0s = Fit runtime\n",
      "\t9 features in original data used to generate 9 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.05 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.03s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 583, Val Rows: 146\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t0.726\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t0.726\t = Validation score   (accuracy)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t0.8082\t = Validation score   (accuracy)\n",
      "\t0.52s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t0.8151\t = Validation score   (accuracy)\n",
      "\t0.46s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.8151\t = Validation score   (accuracy)\n",
      "\t0.41s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.8151\t = Validation score   (accuracy)\n",
      "\t0.37s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t0.8151\t = Validation score   (accuracy)\n",
      "\t1.55s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.8082\t = Validation score   (accuracy)\n",
      "\t0.38s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.7877\t = Validation score   (accuracy)\n",
      "\t0.36s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t0.8014\t = Validation score   (accuracy)\n",
      "\t0.6s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.8425\t = Validation score   (accuracy)\n",
      "\t0.47s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.8014\t = Validation score   (accuracy)\n",
      "\t5.89s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t0.8082\t = Validation score   (accuracy)\n",
      "\t2.47s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'XGBoost': 1.0}\n",
      "\t0.8425\t = Validation score   (accuracy)\n",
      "\t0.2s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 14.3s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20250320_140736\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance with Raw Data (AutoGluon Preprocessing): {'accuracy': 0.9382716049382716, 'balanced_accuracy': 0.9177894064878123, 'mcc': 0.8615672528814801, 'roc_auc': 0.9707779663010062, 'f1': 0.9036402569593148, 'precision': 0.9590909090909091, 'recall': 0.854251012145749}\n",
      "   num__Unnamed: 0  num__Pregnancies  num__Glucose  num__BloodPressure  \\\n",
      "0        -1.729677          0.640733      0.928449           -0.024242   \n",
      "1        -1.724925         -0.857325     -1.200742           -0.518338   \n",
      "2        -1.720173          1.239957      2.111334           -0.683037   \n",
      "3        -1.715421         -0.857325     -1.065555           -0.518338   \n",
      "4        -1.710669          0.341122     -0.153045            0.140457   \n",
      "\n",
      "   num__SkinThickness  num__Insulin  num__BMI  num__DiabetesPedigreeFunction  \\\n",
      "0            0.692857      0.367315  0.195747                       0.572044   \n",
      "1            0.021786     -1.062642 -0.845724                      -0.352984   \n",
      "2           -0.336118      0.310324 -1.336703                       0.722864   \n",
      "3           -0.649285     -0.604123 -0.622552                      -0.969670   \n",
      "4           -0.917713     -0.490141 -0.994506                      -0.855717   \n",
      "\n",
      "   num__Age  Outcome  \n",
      "0  1.516238      1.0  \n",
      "1 -0.162264      0.0  \n",
      "2 -0.073921      1.0  \n",
      "3 -1.045685      0.0  \n",
      "4 -0.250606      0.0  \n"
     ]
    }
   ],
   "source": [
    "# Define the target column\n",
    "target_column = \"Outcome\"\n",
    "\n",
    "# Initialize TabularPredictor with raw data\n",
    "predictor_raw = TabularPredictor(label=target_column).fit(train_data=data)\n",
    "\n",
    "# Evaluate on the test set\n",
    "performance_raw = predictor_raw.evaluate(data)\n",
    "print(\"Performance with Raw Data (AutoGluon Preprocessing):\", performance_raw)\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop(columns=[target_column])\n",
    "y = data[target_column]\n",
    "\n",
    "# Define preprocessing for numerical and categorical features\n",
    "numerical_features = X.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
    "categorical_features = X.select_dtypes(include=[\"object\"]).columns\n",
    "\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")),  # Fill missing values with mean\n",
    "    (\"scaler\", StandardScaler())  # Scale numerical features\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),  # Fill missing values with mode\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))  # Encode categorical features\n",
    "])\n",
    "\n",
    "# Combine preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numerical_transformer, numerical_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Apply preprocessing\n",
    "X_processed = preprocessor.fit_transform(X)\n",
    "\n",
    "# Convert back to a DataFrame\n",
    "processed_data = pd.DataFrame(X_processed, columns=preprocessor.get_feature_names_out())\n",
    "processed_data[target_column] = y\n",
    "\n",
    "# Display the first few rows of processed data\n",
    "print(processed_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "21859b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20250321_083611\"\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20250321_083611\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.9.21\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          32\n",
      "Memory Avail:       2.75 GB / 15.63 GB (17.6%)\n",
      "Disk Space Avail:   672.17 GB / 924.37 GB (72.7%)\n",
      "===================================================\n",
      "Train Data Rows:    583\n",
      "Train Data Columns: 9\n",
      "Label Column:       Outcome\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [0.0, 1.0]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2815.69 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.04 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 8 | ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', ...]\n",
      "\t\t('int', [])   : 1 | ['Unnamed: 0']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 8 | ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', ...]\n",
      "\t\t('int', [])   : 1 | ['Unnamed: 0']\n",
      "\t0.0s = Fit runtime\n",
      "\t9 features in original data used to generate 9 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.04 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.04s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 466, Val Rows: 117\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t0.4865\t = Validation score   (f1)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t0.4865\t = Validation score   (f1)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (583, 10)\n",
      "Testing data shape: (146, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.7\t = Validation score   (f1)\n",
      "\t0.91s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t0.6588\t = Validation score   (f1)\n",
      "\t0.86s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.6341\t = Validation score   (f1)\n",
      "\t0.33s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.6173\t = Validation score   (f1)\n",
      "\t0.29s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t0.625\t = Validation score   (f1)\n",
      "\t0.81s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.6133\t = Validation score   (f1)\n",
      "\t0.35s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.6053\t = Validation score   (f1)\n",
      "\t0.34s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "No improvement since epoch 6: early stopping\n",
      "\t0.75\t = Validation score   (f1)\n",
      "\t0.86s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.6667\t = Validation score   (f1)\n",
      "\t0.67s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.7654\t = Validation score   (f1)\n",
      "\t1.69s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t0.6988\t = Validation score   (f1)\n",
      "\t1.95s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'NeuralNetTorch': 0.933, 'LightGBMLarge': 0.067}\n",
      "\t0.7805\t = Validation score   (f1)\n",
      "\t0.19s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 9.86s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20250321_083611\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  model  score_val eval_metric  pred_time_val  fit_time  \\\n",
      "0   WeightedEnsemble_L2   0.780488          f1       0.024220  3.825591   \n",
      "1        NeuralNetTorch   0.765432          f1       0.015796  1.685366   \n",
      "2       NeuralNetFastAI   0.750000          f1       0.007416  0.860039   \n",
      "3            LightGBMXT   0.700000          f1       0.013973  0.908449   \n",
      "4         LightGBMLarge   0.698795          f1       0.008423  1.946876   \n",
      "5               XGBoost   0.666667          f1       0.006173  0.669173   \n",
      "6              LightGBM   0.658824          f1       0.009454  0.860232   \n",
      "7      RandomForestGini   0.634146          f1       0.032137  0.333944   \n",
      "8              CatBoost   0.625000          f1       0.000000  0.806008   \n",
      "9      RandomForestEntr   0.617284          f1       0.051039  0.286753   \n",
      "10       ExtraTreesGini   0.613333          f1       0.058609  0.345797   \n",
      "11       ExtraTreesEntr   0.605263          f1       0.053820  0.341422   \n",
      "12       KNeighborsUnif   0.486486          f1       0.017036  0.006289   \n",
      "13       KNeighborsDist   0.486486          f1       0.028764  0.000000   \n",
      "\n",
      "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
      "0                 0.000000           0.193349            2       True   \n",
      "1                 0.015796           1.685366            1       True   \n",
      "2                 0.007416           0.860039            1       True   \n",
      "3                 0.013973           0.908449            1       True   \n",
      "4                 0.008423           1.946876            1       True   \n",
      "5                 0.006173           0.669173            1       True   \n",
      "6                 0.009454           0.860232            1       True   \n",
      "7                 0.032137           0.333944            1       True   \n",
      "8                 0.000000           0.806008            1       True   \n",
      "9                 0.051039           0.286753            1       True   \n",
      "10                0.058609           0.345797            1       True   \n",
      "11                0.053820           0.341422            1       True   \n",
      "12                0.017036           0.006289            1       True   \n",
      "13                0.028764           0.000000            1       True   \n",
      "\n",
      "    fit_order  \n",
      "0          14  \n",
      "1          12  \n",
      "2          10  \n",
      "3           3  \n",
      "4          13  \n",
      "5          11  \n",
      "6           4  \n",
      "7           5  \n",
      "8           7  \n",
      "9           6  \n",
      "10          8  \n",
      "11          9  \n",
      "12          1  \n",
      "13          2  \n",
      "Test Set Performance: {'f1': 0.6947368421052631, 'accuracy': 0.8013698630136986, 'balanced_accuracy': 0.7697243845992006, 'mcc': 0.548346654127046, 'roc_auc': 0.8781822007153376, 'precision': 0.717391304347826, 'recall': 0.673469387755102}\n",
      "Predictions on Test Set: 468    1.0\n",
      "148    0.0\n",
      "302    1.0\n",
      "355    0.0\n",
      "515    1.0\n",
      "      ... \n",
      "404    0.0\n",
      "390    1.0\n",
      "218    1.0\n",
      "135    1.0\n",
      "260    0.0\n",
      "Name: Outcome, Length: 146, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the target column\n",
    "target_column = \"Outcome\"\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "X = data.drop(columns=[target_column])\n",
    "y = data[target_column]\n",
    "\n",
    "# Split into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Combine features and target for AutoGluon\n",
    "train_data = pd.concat([X_train, y_train], axis=1)\n",
    "test_data = pd.concat([X_test, y_test], axis=1)\n",
    "\n",
    "# Display the shapes of the training and testing sets\n",
    "print(\"Training data shape:\", train_data.shape)\n",
    "print(\"Testing data shape:\", test_data.shape)\n",
    "\n",
    "# Initialize TabularPredictor\n",
    "predictor = TabularPredictor(label=target_column, eval_metric= \"f1\").fit(train_data=train_data)\n",
    "\n",
    "# Display the model leaderboard\n",
    "leaderboard = predictor.leaderboard()\n",
    "print(leaderboard)\n",
    "performance = predictor.evaluate(test_data)\n",
    "print(\"Test Set Performance:\", performance)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = predictor.predict(test_data)\n",
    "print(\"Predictions on Test Set:\", y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5937d7",
   "metadata": {},
   "source": [
    "### Use the Autogluon library\n",
    "Use the library autogluon for automated hyperparametertuning and model benchmarking. The fit function of the TabularPredictor object allows for setting the option: <br>\n",
    "<i>presets = {‘best_quality’, ‘high_quality’, ‘good_quality’, ‘medium_quality’, ‘experimental_quality’, ‘optimize_for_deployment’, ‘interpretable’, ‘ignore_text’}</i> <br>\n",
    "\n",
    "medium_quality can limit the depths of hyperparameter optimization.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878256be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d414ebe",
   "metadata": {},
   "source": [
    "### Show the leaderboard\n",
    "TabularPredictor objects from Autogluon provide a function \"leaderboard\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06190c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a513f67a",
   "metadata": {},
   "source": [
    "### Show the feature importance table\n",
    "The TabularPredictor class from Autogluon also provides a function \"feature_importance\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c29e109",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aa_tuesday",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 49.933279,
   "end_time": "2021-09-20T20:03:41.801824",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-09-20T20:02:51.868545",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
